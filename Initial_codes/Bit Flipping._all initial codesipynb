{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing packages"
      ],
      "metadata": {
        "id": "XqKxOv2dduOM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iU-Qwp_9aVzh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy import sparse as sp\n",
        "import scipy.sparse.linalg"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bit Flipping algorithm"
      ],
      "metadata": {
        "id": "W7lkYvmxeC5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gallagerA(H, err_codeword, n_iter):\n",
        "  \"\"\"\n",
        "  Parameters:\n",
        "  H: parity check matrix (sparse matrix)\n",
        "  err_codeword: transmitted codeword\n",
        "  n_iter: number of iterations\n",
        "  Returns\n",
        "  Corrected code if found within the given number of iterations, n_iter;\n",
        "  along with the iteration step it was found.\n",
        "  \"\"\"\n",
        "  # H = sp.csr_matrix(H)\n",
        "  corrected_codeword = err_codeword\n",
        "  for i in range(n_iter):\n",
        "    syndrome = H.dot(corrected_codeword) % 2\n",
        "    unsatisfied_check_indices = np.where(syndrome == 1)[0]\n",
        "    print(unsatisfied_check_indices)\n",
        "    if np.sum(syndrome) == 0:\n",
        "      print(\"Corrected codeword\")\n",
        "      return corrected_codeword, i\n",
        "    no_ones = np.sum(H, axis=0)\n",
        "    # for syn, j in enumerate(syndrome):\n",
        "    #   if syn ==\n",
        "  return corrected_codeword, n_iter\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    H = np.array([\n",
        "        [1, 1, 0, 1, 0, 0],\n",
        "        [0, 1, 1, 0, 1, 0],\n",
        "        [1, 1, 1, 0, 0, 1]\n",
        "    ])\n",
        "\n",
        "    original_codeword = np.array([0, 0, 0, 0, 0, 0])\n",
        "    error_pattern = np.array([0, 1, 0, 0, 0, 0])\n",
        "    received_codeword = (original_codeword + error_pattern)%2\n",
        "\n",
        "    print(\"Original Codeword:\", original_codeword)\n",
        "    print(\"Received Codeword:\", received_codeword)\n",
        "\n",
        "    decoded_codeword, iterations = gallagerA(H, received_codeword, 100)\n",
        "\n",
        "    print(\"Decoded Codeword:\", decoded_codeword)\n",
        "    print(\"Iterations:\", iterations)\n",
        "\n",
        "    # print(H.dot(decoded_codeword) % 2)\n",
        "    no_ones = np.sum(H, axis=0)\n",
        "    print(no_ones)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vRormhJd9OO",
        "outputId": "e9b9b70a-5851-4024-a06f-530e331513ed"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Codeword: [0 0 0 0 0 0]\n",
            "Received Codeword: [0 1 0 0 0 0]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "[0 1 2]\n",
            "Decoded Codeword: [0 1 0 0 0 0]\n",
            "Iterations: 100\n",
            "[2 3 2 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from itertools import combinations\n",
        "\n",
        "def find_common_variable_nodes(H, syndrome):\n",
        "    \"\"\"\n",
        "    Find common variable nodes connected to unsatisfied check nodes.\n",
        "\n",
        "    Parameters:\n",
        "        H (numpy.ndarray): Parity-check matrix (m x n).\n",
        "        syndrome (numpy.ndarray): Syndrome vector (1 x m).\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are common variable node indices and values are their counts.\n",
        "    \"\"\"\n",
        "    # Step 1: Find indices where syndrome is 1 (unsatisfied check nodes)\n",
        "    unsatisfied_check_indices = np.where(syndrome == 1)[0]\n",
        "    num_unsatisfied = len(unsatisfied_check_indices)\n",
        "\n",
        "    # Dictionary to store common variable nodes and their counts\n",
        "    common_variable_counts = {}\n",
        "\n",
        "    # Set to keep track of check nodes that have already been processed in larger combinations\n",
        "    processed_check_nodes = set()\n",
        "\n",
        "    # Step 2: Check for common variable nodes in all possible combinations of unsatisfied check nodes\n",
        "    if num_unsatisfied > 0:\n",
        "        # Start with the largest combination (all unsatisfied check nodes) and work down to pairs\n",
        "        for r in range(num_unsatisfied, 1, -1):\n",
        "            # Generate all combinations of size r\n",
        "            for combo in combinations(unsatisfied_check_indices, r):\n",
        "                # Skip if any check node in this combination has already been processed\n",
        "                if any(check_node in processed_check_nodes for check_node in combo):\n",
        "                    continue\n",
        "                else:\n",
        "                  # Get the variable nodes for the current combination of check nodes\n",
        "                  variable_node_sets = []\n",
        "                  for check_index in combo:\n",
        "                      row = H[check_index, :]\n",
        "                      variable_nodes = np.where(row == 1)[0]\n",
        "                      variable_node_sets.append(set(variable_nodes))\n",
        "\n",
        "                  # Find intersection (common variable nodes for this combination)\n",
        "                  common_nodes = set.intersection(*variable_node_sets)\n",
        "\n",
        "                  # If common variable nodes are found, update the dictionary and mark check nodes as processed\n",
        "                  if common_nodes:\n",
        "                      for var_node in common_nodes:\n",
        "                          if var_node in common_variable_counts:\n",
        "                              common_variable_counts[var_node] += 1\n",
        "                          else:\n",
        "                              common_variable_counts[var_node] = 1\n",
        "\n",
        "                      # Mark all check nodes in this combination as processed\n",
        "                      processed_check_nodes.update(combo)\n",
        "\n",
        "    return common_variable_counts\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Define a parity-check matrix H\n",
        "    H = np.array([\n",
        "        [1, 1, 0, 1, 0, 0],\n",
        "        [0, 1, 1, 0, 1, 0],\n",
        "        [1, 0, 0, 0, 1, 1],\n",
        "        [0, 0, 1, 1, 0, 1]\n",
        "    ])\n",
        "\n",
        "    # Define a syndrome vector\n",
        "    syndrome = np.array([1, 1, 0, 1])  # Example syndrome with unsatisfied check nodes\n",
        "\n",
        "    print(\"Parity-Check Matrix H:\")\n",
        "    print(H)\n",
        "    print(\"Syndrome:\", syndrome)\n",
        "\n",
        "    # Find common variable nodes and their counts\n",
        "    common_variable_counts = find_common_variable_nodes(H, syndrome)\n",
        "\n",
        "    print(\"Common Variable Nodes and Their Counts:\")\n",
        "    print(common_variable_counts)"
      ],
      "metadata": {
        "id": "IzqYDVSBQupr",
        "outputId": "0d057d85-e03e-41d7-e2d1-2820010b23ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 112)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m112\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from itertools import combinations\n",
        "\n",
        "def find_common_variable_nodes(H, syndrome):\n",
        "    \"\"\"\n",
        "    Find common variable nodes connected to unsatisfied check nodes.\n",
        "\n",
        "    Parameters:\n",
        "        H (numpy.ndarray): Parity-check matrix (m x n).\n",
        "        syndrome (numpy.ndarray): Syndrome vector (1 x m).\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are common variable node indices and values are their counts.\n",
        "    \"\"\"\n",
        "    # Step 1: Find indices where syndrome is 1 (unsatisfied check nodes)\n",
        "    unsatisfied_check_indices = np.where(syndrome == 1)[0]\n",
        "    num_unsatisfied = len(unsatisfied_check_indices)\n",
        "\n",
        "    # Dictionary to store common variable nodes and their counts\n",
        "    common_variable_counts = {}\n",
        "\n",
        "    # Step 2: Check for common variable nodes in all possible combinations of unsatisfied check nodes\n",
        "    if num_unsatisfied > 0:\n",
        "        # Start with the largest combination (all unsatisfied check nodes) and work down to pairs\n",
        "        for r in range(num_unsatisfied, 1, -1):\n",
        "            # Generate all combinations of size r\n",
        "            for combo in combinations(unsatisfied_check_indices, r):\n",
        "                # Get the variable nodes for the current combination of check nodes\n",
        "                variable_node_sets = []\n",
        "                for check_index in combo:\n",
        "                    row = H[check_index, :]\n",
        "                    variable_nodes = np.where(row == 1)[0]\n",
        "                    variable_node_sets.append(set(variable_nodes))\n",
        "\n",
        "                # Find intersection (common variable nodes for this combination)\n",
        "                common_nodes = set.intersection(*variable_node_sets)\n",
        "\n",
        "                # Update the dictionary with counts\n",
        "                for var_node in common_nodes:\n",
        "                    if var_node in common_variable_counts:\n",
        "                        common_variable_counts[var_node] += 1\n",
        "                    else:\n",
        "                        common_variable_counts[var_node] = 1\n",
        "\n",
        "    return common_variable_counts\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Define a parity-check matrix H\n",
        "    H = np.array([\n",
        "        [1, 1, 0, 1, 0, 0],\n",
        "        [0, 1, 1, 0, 1, 0],\n",
        "        [1, 0, 0, 0, 1, 1],\n",
        "        [0, 0, 1, 1, 0, 1]\n",
        "    ])\n",
        "\n",
        "    # Define a syndrome vector\n",
        "    syndrome = np.array([1, 1, 0, 1])  # Unsatisfied check nodes: 0, 1, 3\n",
        "\n",
        "    print(\"Parity-Check Matrix H:\")\n",
        "    print(H)\n",
        "    print(\"Syndrome:\", syndrome)\n",
        "\n",
        "    # Find common variable nodes and their counts\n",
        "    common_variable_counts = find_common_variable_nodes(H, syndrome)\n",
        "\n",
        "    print(\"Common Variable Nodes and Their Counts:\")\n",
        "    print(common_variable_counts)"
      ],
      "metadata": {
        "id": "0T9MkYCDh5lg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21ee24c0-5104-4c4b-9f5f-9d4d52b7b32e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parity-Check Matrix H:\n",
            "[[1 1 0 1 0 0]\n",
            " [0 1 1 0 1 0]\n",
            " [1 0 0 0 1 1]\n",
            " [0 0 1 1 0 1]]\n",
            "Syndrome: [1 1 0 1]\n",
            "Common Variable Nodes and Their Counts:\n",
            "{1: 1, 3: 1, 2: 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from itertools import combinations\n",
        "\n",
        "def find_common_variable_nodes(H, syndrome):\n",
        "    \"\"\"\n",
        "    Find common variable nodes connected to unsatisfied check nodes.\n",
        "\n",
        "    Parameters:\n",
        "        H (numpy.ndarray): Parity-check matrix (m x n).\n",
        "        syndrome (numpy.ndarray): Syndrome vector (1 x m).\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are common variable node indices and values are their counts.\n",
        "    \"\"\"\n",
        "    # Step 1: Find indices where syndrome is 1 (unsatisfied check nodes)\n",
        "    unsatisfied_check_indices = np.where(syndrome == 1)[0]\n",
        "    num_unsatisfied = len(unsatisfied_check_indices)\n",
        "\n",
        "    # Dictionary to store common variable nodes and their counts\n",
        "    common_variable_counts = {}\n",
        "\n",
        "    # Set to keep track of processed combinations of check nodes\n",
        "    processed_combinations = set()\n",
        "\n",
        "    # Step 2: Check for common variable nodes in all possible combinations of unsatisfied check nodes\n",
        "    if num_unsatisfied > 0:\n",
        "        # Start with the largest combination (all unsatisfied check nodes) and work down to pairs\n",
        "        for r in range(num_unsatisfied, 1, -1):\n",
        "            # Generate all combinations of size r\n",
        "            for combo in combinations(unsatisfied_check_indices, r):\n",
        "                # Skip if this combination is a subset of any previously processed combination\n",
        "                if any(set(combo).issubset(processed) for processed in processed_combinations):\n",
        "                    continue\n",
        "\n",
        "                # Get the variable nodes for the current combination of check nodes\n",
        "                variable_node_sets = []\n",
        "                for check_index in combo:\n",
        "                    row = H[check_index, :]\n",
        "                    variable_nodes = np.where(row == 1)[0]\n",
        "                    variable_node_sets.append(set(variable_nodes))\n",
        "\n",
        "                # Find intersection (common variable nodes for this combination)\n",
        "                common_nodes = set.intersection(*variable_node_sets)\n",
        "\n",
        "                # If common variable nodes are found, update the dictionary and mark the combination as processed\n",
        "                if common_nodes:\n",
        "                    for var_node in common_nodes:\n",
        "                        if var_node in common_variable_counts:\n",
        "                            common_variable_counts[var_node] += 1\n",
        "                        else:\n",
        "                            common_variable_counts[var_node] = 1\n",
        "\n",
        "                    # Mark this combination as processed\n",
        "                    processed_combinations.add(frozenset(combo))\n",
        "\n",
        "    return common_variable_counts\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Define a parity-check matrix H\n",
        "    # H = np.array([\n",
        "    #     [1, 1, 0, 1, 0, 0],\n",
        "    #     [0, 1, 1, 0, 1, 0],\n",
        "    #     [1, 0, 0, 0, 1, 1],\n",
        "    #     [0, 0, 1, 1, 0, 1]\n",
        "    # ])\n",
        "\n",
        "    # # Define a syndrome vector\n",
        "    # syndrome = np.array([1, 1, 0, 1])  # Unsatisfied check nodes: 0, 1, 3\n",
        "\n",
        "    print(\"Parity-Check Matrix H:\")\n",
        "    print(H)\n",
        "    print(\"Syndrome:\", syndrome)\n",
        "\n",
        "    # Find common variable nodes and their counts\n",
        "    common_variable_counts = find_common_variable_nodes(H, syndrome)\n",
        "\n",
        "    print(\"Common Variable Nodes and Their Counts:\")\n",
        "    print(common_variable_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X_-7OGvDr6d",
        "outputId": "bb9390c2-d5fa-44af-996a-da64b9f24dc8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parity-Check Matrix H:\n",
            "[[1 1 0 1 0 0]\n",
            " [0 1 1 0 1 0]\n",
            " [1 1 1 0 0 1]]\n",
            "Syndrome: [0 1 0]\n",
            "Common Variable Nodes and Their Counts:\n",
            "{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from itertools import combinations\n",
        "\n",
        "def find_common_variable_nodes(H, syndrome):\n",
        "    \"\"\"\n",
        "    Find common variable nodes connected to unsatisfied check nodes.\n",
        "\n",
        "    Parameters:\n",
        "        H (numpy.ndarray): Parity-check matrix (m x n).\n",
        "        syndrome (numpy.ndarray): Syndrome vector (1 x m).\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are variable node indices and values are their counts.\n",
        "    \"\"\"\n",
        "    # Check for invalid input dimensions\n",
        "    m, n = H.shape\n",
        "    if len(syndrome) != m:\n",
        "        raise ValueError(\"Dimensions of H and syndrome do not match.\")\n",
        "\n",
        "    # Step 1: Find indices where syndrome is non-zero (unsatisfied check nodes)\n",
        "    unsatisfied_check_indices = np.where(syndrome != 0)[0]\n",
        "    num_unsatisfied = len(unsatisfied_check_indices)\n",
        "\n",
        "    # Dictionary to store variable nodes and their counts\n",
        "    variable_counts = {}\n",
        "\n",
        "    # Step 2: Handle the case where there are no unsatisfied check nodes\n",
        "    if num_unsatisfied == 0:\n",
        "        return variable_counts\n",
        "\n",
        "    # Step 3: Handle the case where there is only one unsatisfied check node\n",
        "    if num_unsatisfied == 1:\n",
        "        # Get the unsatisfied check node\n",
        "        unsatisfied_check_index = unsatisfied_check_indices[0]\n",
        "\n",
        "        # Get the variable nodes connected to the unsatisfied check node\n",
        "        unsatisfied_variable_nodes = set(np.where(H[unsatisfied_check_index, :] == 1)[0])\n",
        "\n",
        "        # Get the satisfied check nodes\n",
        "        satisfied_check_indices = np.where(syndrome == 0)[0]\n",
        "\n",
        "        # Get the variable nodes connected to the satisfied check nodes\n",
        "        satisfied_variable_nodes = set()\n",
        "        for check_index in satisfied_check_indices:\n",
        "            satisfied_variable_nodes.update(np.where(H[check_index, :] == 1)[0])\n",
        "\n",
        "        # Find variable nodes that are connected to the unsatisfied check node but not to any satisfied check node\n",
        "        uncommon_variable_nodes = unsatisfied_variable_nodes - satisfied_variable_nodes\n",
        "\n",
        "        # Update the dictionary\n",
        "        for var_node in uncommon_variable_nodes:\n",
        "            variable_counts[var_node] = 1\n",
        "\n",
        "        return variable_counts\n",
        "\n",
        "    # Step 4: Check for common variable nodes in all possible combinations of unsatisfied check nodes\n",
        "    if num_unsatisfied > 1:\n",
        "        # Set to keep track of processed combinations of check nodes\n",
        "        processed_combinations = set()\n",
        "\n",
        "        # Start with the largest combination (all unsatisfied check nodes) and work down to pairs\n",
        "        for r in range(num_unsatisfied, 1, -1):\n",
        "            # Generate all combinations of size r\n",
        "            for combo in combinations(unsatisfied_check_indices, r):\n",
        "                # Skip if this combination is a subset of any previously processed combination\n",
        "                if any(set(combo).issubset(processed) for processed in processed_combinations):\n",
        "                    continue\n",
        "\n",
        "                # Get the variable nodes for the current combination of check nodes\n",
        "                variable_node_sets = []\n",
        "                for check_index in combo:\n",
        "                    row = H[check_index, :]\n",
        "                    variable_nodes = np.where(row == 1)[0]\n",
        "                    variable_node_sets.append(set(variable_nodes))\n",
        "\n",
        "                # Find intersection (common variable nodes for this combination)\n",
        "                common_nodes = set.intersection(*variable_node_sets)\n",
        "\n",
        "                # If common variable nodes are found, update the dictionary and mark the combination as processed\n",
        "                if common_nodes:\n",
        "                    for var_node in common_nodes:\n",
        "                        if var_node in variable_counts:\n",
        "                            variable_counts[var_node] += 1\n",
        "                        else:\n",
        "                            variable_counts[var_node] = 1\n",
        "\n",
        "                    # Mark this combination as processed\n",
        "                    processed_combinations.add(frozenset(combo))\n",
        "\n",
        "    return variable_counts\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Define a parity-check matrix H\n",
        "    # H = np.array([\n",
        "    #     [1, 1, 0, 1, 0, 0],\n",
        "    #     [0, 1, 1, 0, 1, 0],\n",
        "    #     [1, 1, 1, 0, 0, 1]\n",
        "    # ])\n",
        "\n",
        "    # # Define a syndrome vector\n",
        "    # syndrome = np.array([0, 1, 0])  # Unsatisfied check node: 1\n",
        "\n",
        "    H = np.array([\n",
        "        [1, 1, 0, 1, 0, 0],\n",
        "        [0, 1, 1, 0, 1, 0],\n",
        "        [1, 0, 0, 0, 1, 1],\n",
        "        [0, 0, 1, 1, 0, 1]\n",
        "    ])\n",
        "\n",
        "    # Define a syndrome vector\n",
        "    syndrome = np.array([0, 0, 0, 0])  # Unsatisfied check nodes: 0, 1, 3\n",
        "\n",
        "\n",
        "    print(\"Parity-Check Matrix H:\")\n",
        "    print(H)\n",
        "    print(\"Syndrome:\", syndrome)\n",
        "\n",
        "    # Find variable nodes and their counts\n",
        "    variable_counts = find_common_variable_nodes(H, syndrome)\n",
        "\n",
        "    print(\"Variable Nodes and Their Counts:\")\n",
        "    print(variable_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvRSFxp5El6-",
        "outputId": "469ab057-9d62-4dca-b28d-5b1afc87b77d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parity-Check Matrix H:\n",
            "[[1 1 0 1 0 0]\n",
            " [0 1 1 0 1 0]\n",
            " [1 0 0 0 1 1]\n",
            " [0 0 1 1 0 1]]\n",
            "Syndrome: [0 0 0 0]\n",
            "Variable Nodes and Their Counts:\n",
            "{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from itertools import combinations\n",
        "\n",
        "def find_common_variable_nodes(H, syndrome):\n",
        "    \"\"\"\n",
        "    Find common variable nodes connected to unsatisfied check nodes.\n",
        "\n",
        "    Parameters:\n",
        "        H (numpy.ndarray): Parity-check matrix (m x n).\n",
        "        syndrome (numpy.ndarray): Syndrome vector (1 x m).\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are variable node indices and values are their counts.\n",
        "    \"\"\"\n",
        "    # Check for invalid input dimensions\n",
        "    m, n = H.shape\n",
        "    if len(syndrome) != m:\n",
        "        raise ValueError(\"Dimensions of H and syndrome do not match.\")\n",
        "\n",
        "    # Step 1: Find indices where syndrome is non-zero (unsatisfied check nodes)\n",
        "    unsatisfied_check_indices = np.where(syndrome != 0)[0]\n",
        "    num_unsatisfied = len(unsatisfied_check_indices)\n",
        "\n",
        "    # Dictionary to store variable nodes and their counts\n",
        "    variable_counts = {}\n",
        "\n",
        "    # Step 2: Handle the case where there are no unsatisfied check nodes\n",
        "    if num_unsatisfied == 0:\n",
        "        return variable_counts\n",
        "\n",
        "    # Step 3: Handle the case where there is only one unsatisfied check node\n",
        "    if num_unsatisfied == 1:\n",
        "        # Get the unsatisfied check node\n",
        "        unsatisfied_check_index = unsatisfied_check_indices[0]\n",
        "\n",
        "        # Get the variable nodes connected to the unsatisfied check node\n",
        "        unsatisfied_variable_nodes = set(np.where(H[unsatisfied_check_index, :] == 1)[0])\n",
        "\n",
        "        # Get the satisfied check nodes\n",
        "        satisfied_check_indices = np.where(syndrome == 0)[0]\n",
        "\n",
        "        # Get the variable nodes connected to the satisfied check nodes\n",
        "        satisfied_variable_nodes = set()\n",
        "        for check_index in satisfied_check_indices:\n",
        "            satisfied_variable_nodes.update(np.where(H[check_index, :] == 1)[0])\n",
        "\n",
        "        # Find variable nodes that are connected to the unsatisfied check node but not to any satisfied check node\n",
        "        uncommon_variable_nodes = unsatisfied_variable_nodes - satisfied_variable_nodes\n",
        "\n",
        "        # Update the dictionary\n",
        "        for var_node in uncommon_variable_nodes:\n",
        "            variable_counts[var_node] = 1\n",
        "\n",
        "        return variable_counts\n",
        "\n",
        "    # Step 4: Check for common variable nodes in all possible combinations of unsatisfied check nodes\n",
        "    if num_unsatisfied > 1:\n",
        "        # Set to keep track of processed combinations of check nodes\n",
        "        processed_combinations = set()\n",
        "\n",
        "        # Start with the largest combination (all unsatisfied check nodes) and work down to pairs\n",
        "        for r in range(num_unsatisfied, 1, -1):\n",
        "            # Generate all combinations of size r\n",
        "            for combo in combinations(unsatisfied_check_indices, r):\n",
        "                # Skip if this combination is a subset of any previously processed combination\n",
        "                if any(set(combo).issubset(processed) for processed in processed_combinations):\n",
        "                    continue\n",
        "\n",
        "                # Get the variable nodes for the current combination of check nodes\n",
        "                variable_node_sets = []\n",
        "                for check_index in combo:\n",
        "                    row = H[check_index, :]\n",
        "                    variable_nodes = np.where(row == 1)[0]\n",
        "                    variable_node_sets.append(set(variable_nodes))\n",
        "\n",
        "                # Find intersection (common variable nodes for this combination)\n",
        "                common_nodes = set.intersection(*variable_node_sets)\n",
        "\n",
        "                # If common variable nodes are found, update the dictionary and mark the combination as processed\n",
        "                if common_nodes:\n",
        "                    for var_node in common_nodes:\n",
        "                        if var_node in variable_counts:\n",
        "                            variable_counts[var_node] += 1\n",
        "                        else:\n",
        "                            variable_counts[var_node] = 1\n",
        "\n",
        "                    # Mark this combination as processed\n",
        "                    processed_combinations.add(frozenset(combo))\n",
        "\n",
        "    return variable_counts\n",
        "\n",
        "def flip_variable_nodes(H, syndrome, received_codeword):\n",
        "    \"\"\"\n",
        "    Flip variable nodes in the received codeword based on the threshold (number of ones in each column of H).\n",
        "\n",
        "    Parameters:\n",
        "        H (numpy.ndarray): Parity-check matrix (m x n).\n",
        "        syndrome (numpy.ndarray): Syndrome vector (1 x m).\n",
        "        received_codeword (numpy.ndarray): Received codeword (1 x n).\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Decoded codeword (1 x n).\n",
        "    \"\"\"\n",
        "    # Step 1: Find common variable nodes and their counts\n",
        "    variable_counts = find_common_variable_nodes(H, syndrome)\n",
        "    print(variable_counts)\n",
        "\n",
        "    # Step 2: Compute the threshold for each variable node (number of ones in each column of H)\n",
        "    thresholds = np.sum(H, axis=0)\n",
        "\n",
        "    # Step 3: Initialize the decoded codeword as a copy of the received codeword\n",
        "    decoded_codeword = received_codeword.copy()\n",
        "\n",
        "    # Step 4: Flip variable nodes where the count exceeds or equals the threshold\n",
        "    for var_node, count in variable_counts.items():\n",
        "        if count >= thresholds[var_node]:\n",
        "            decoded_codeword[var_node] = 1 - decoded_codeword[var_node]\n",
        "        print(var_node)\n",
        "        print(count)\n",
        "\n",
        "    return decoded_codeword\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Define a parity-check matrix H\n",
        "    # H = np.array([\n",
        "    #     [1, 1, 0, 1, 0, 0],\n",
        "    #     [0, 1, 1, 0, 1, 0],\n",
        "    #     [1, 1, 1, 0, 0, 1]\n",
        "    # ])\n",
        "\n",
        "    H = np.array([\n",
        "        [1, 1, 0, 1, 0, 0],\n",
        "        [0, 1, 1, 0, 1, 0],\n",
        "        [1, 0, 0, 0, 1, 1],\n",
        "        [0, 0, 1, 1, 0, 1]\n",
        "    ])\n",
        "\n",
        "\n",
        "    # Define the original codeword and error pattern\n",
        "    original_codeword = np.array([0, 0, 0, 0, 0, 0])\n",
        "    error_pattern = np.array([0, 1, 0, 0, 0, 0])\n",
        "\n",
        "    # Compute the received codeword\n",
        "    received_codeword = (original_codeword + error_pattern) % 2\n",
        "\n",
        "    print(\"Original Codeword:\", original_codeword)\n",
        "    print(\"Error Pattern:\", error_pattern)\n",
        "    print(\"Received Codeword:\", received_codeword)\n",
        "\n",
        "    # Compute the syndrome\n",
        "    syndrome = np.mod(H @ received_codeword, 2)\n",
        "\n",
        "    print(\"Syndrome:\", syndrome)\n",
        "\n",
        "    # Flip variable nodes based on the threshold\n",
        "    decoded_codeword = flip_variable_nodes(H, syndrome, received_codeword)\n",
        "\n",
        "    print(\"Decoded Codeword:\")\n",
        "    print(decoded_codeword)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ttco-4R5KDTd",
        "outputId": "f4c05098-bfe7-4f45-b46b-aed591680cc5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Codeword: [0 0 0 0 0 0]\n",
            "Error Pattern: [0 1 0 0 0 0]\n",
            "Received Codeword: [0 1 0 0 0 0]\n",
            "Syndrome: [1 1 0 0]\n",
            "{1: 1}\n",
            "1\n",
            "1\n",
            "Decoded Codeword:\n",
            "[0 1 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from itertools import combinations\n",
        "\n",
        "def find_common_variable_nodes(H, syndrome):\n",
        "    \"\"\"\n",
        "    Find common variable nodes connected to unsatisfied check nodes.\n",
        "\n",
        "    Parameters:\n",
        "        H (numpy.ndarray): Parity-check matrix (m x n).\n",
        "        syndrome (numpy.ndarray): Syndrome vector (1 x m).\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are variable node indices and values are their counts.\n",
        "    \"\"\"\n",
        "    # Check for invalid input dimensions\n",
        "    m, n = H.shape\n",
        "    if len(syndrome) != m:\n",
        "        raise ValueError(\"Dimensions of H and syndrome do not match.\")\n",
        "\n",
        "    # Step 1: Find indices where syndrome is non-zero (unsatisfied check nodes)\n",
        "    unsatisfied_check_indices = np.where(syndrome != 0)[0]\n",
        "    num_unsatisfied = len(unsatisfied_check_indices)\n",
        "\n",
        "    # Dictionary to store variable nodes and their counts\n",
        "    variable_counts = {}\n",
        "\n",
        "    # Step 2: Handle the case where there are no unsatisfied check nodes\n",
        "    if num_unsatisfied == 0:\n",
        "        return variable_counts\n",
        "\n",
        "    # Step 3: Handle the case where there is only one unsatisfied check node\n",
        "    if num_unsatisfied == 1:\n",
        "        # Get the unsatisfied check node\n",
        "        unsatisfied_check_index = unsatisfied_check_indices[0]\n",
        "\n",
        "        # Get the variable nodes connected to the unsatisfied check node\n",
        "        unsatisfied_variable_nodes = set(np.where(H[unsatisfied_check_index, :] == 1)[0])\n",
        "\n",
        "        # Get the satisfied check nodes\n",
        "        satisfied_check_indices = np.where(syndrome == 0)[0]\n",
        "\n",
        "        # Get the variable nodes connected to the satisfied check nodes\n",
        "        satisfied_variable_nodes = set()\n",
        "        for check_index in satisfied_check_indices:\n",
        "            satisfied_variable_nodes.update(np.where(H[check_index, :] == 1)[0])\n",
        "\n",
        "        # Find variable nodes that are connected to the unsatisfied check node but not to any satisfied check node\n",
        "        uncommon_variable_nodes = unsatisfied_variable_nodes - satisfied_variable_nodes\n",
        "\n",
        "        # Update the dictionary\n",
        "        for var_node in uncommon_variable_nodes:\n",
        "            variable_counts[var_node] = 1\n",
        "\n",
        "        return variable_counts\n",
        "\n",
        "    # Step 4: Check for common variable nodes in all possible combinations of unsatisfied check nodes\n",
        "    if num_unsatisfied > 1:\n",
        "        # Set to keep track of processed combinations of check nodes\n",
        "        processed_combinations = set()\n",
        "\n",
        "        # Start with the largest combination (all unsatisfied check nodes) and work down to pairs\n",
        "        for r in range(num_unsatisfied, 1, -1):\n",
        "            # Generate all combinations of size r\n",
        "            for combo in combinations(unsatisfied_check_indices, r):\n",
        "                # Skip if this combination is a subset of any previously processed combination\n",
        "                if any(set(combo).issubset(processed) for processed in processed_combinations):\n",
        "                    continue\n",
        "\n",
        "                # Get the variable nodes for the current combination of check nodes\n",
        "                variable_node_sets = []\n",
        "                for check_index in combo:\n",
        "                    row = H[check_index, :]\n",
        "                    variable_nodes = np.where(row == 1)[0]\n",
        "                    variable_node_sets.append(set(variable_nodes))\n",
        "\n",
        "                # Find intersection (common variable nodes for this combination)\n",
        "                common_nodes = set.intersection(*variable_node_sets)\n",
        "\n",
        "                # If common variable nodes are found, update the dictionary and mark the combination as processed\n",
        "                if common_nodes:\n",
        "                    for var_node in common_nodes:\n",
        "                        if var_node in variable_counts:\n",
        "                            variable_counts[var_node] += len(combo)  # Increment by the size of the combination\n",
        "                        else:\n",
        "                            variable_counts[var_node] = len(combo)  # Initialize with the size of the combination\n",
        "\n",
        "                    # Mark this combination as processed\n",
        "                    processed_combinations.add(frozenset(combo))\n",
        "\n",
        "    return variable_counts\n",
        "\n",
        "def flip_variable_nodes(H, syndrome, received_codeword):\n",
        "    \"\"\"\n",
        "    Flip variable nodes in the received codeword based on the threshold (number of ones in each column of H).\n",
        "\n",
        "    Parameters:\n",
        "        H (numpy.ndarray): Parity-check matrix (m x n).\n",
        "        syndrome (numpy.ndarray): Syndrome vector (1 x m).\n",
        "        received_codeword (numpy.ndarray): Received codeword (1 x n).\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Decoded codeword (1 x n).\n",
        "    \"\"\"\n",
        "    # Step 1: Find common variable nodes and their counts\n",
        "    variable_counts = find_common_variable_nodes(H, syndrome)\n",
        "\n",
        "    # Step 2: Compute the threshold for each variable node (number of ones in each column of H)\n",
        "    thresholds = np.sum(H, axis=0)\n",
        "\n",
        "    # Step 3: Initialize the decoded codeword as a copy of the received codeword\n",
        "    decoded_codeword = received_codeword.copy()\n",
        "\n",
        "    # Step 4: Flip variable nodes where the count exceeds or equals the threshold\n",
        "    for var_node, count in variable_counts.items():\n",
        "        if count >= thresholds[var_node]:\n",
        "            decoded_codeword[var_node] = 1 - decoded_codeword[var_node]\n",
        "\n",
        "    return decoded_codeword\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Define a parity-check matrix H\n",
        "    # H = np.array([\n",
        "    #     [1, 1, 0, 1, 0, 0],\n",
        "    #     [0, 1, 1, 0, 1, 0],\n",
        "    #     [1, 1, 1, 0, 0, 1]\n",
        "    # ])\n",
        "    H = np.array([\n",
        "        [1, 1, 0, 1, 0, 0],\n",
        "        [0, 1, 1, 0, 1, 0],\n",
        "        [1, 0, 0, 0, 1, 1],\n",
        "        [0, 0, 1, 1, 0, 1]\n",
        "    ])\n",
        "    # Define the original codeword and error pattern\n",
        "    original_codeword = np.array([0, 0, 0, 0, 0, 0])\n",
        "    error_pattern = np.array([0, 1, 0, 0, 0, 0])\n",
        "\n",
        "    # Compute the received codeword\n",
        "    received_codeword = (original_codeword + error_pattern) % 2\n",
        "\n",
        "    print(\"Original Codeword:\", original_codeword)\n",
        "    print(\"Error Pattern:\", error_pattern)\n",
        "    print(\"Received Codeword:\", received_codeword)\n",
        "\n",
        "    # Compute the syndrome\n",
        "    syndrome = np.mod(H @ received_codeword, 2)\n",
        "\n",
        "    print(\"Syndrome:\", syndrome)\n",
        "\n",
        "    # Flip variable nodes based on the threshold\n",
        "    decoded_codeword = flip_variable_nodes(H, syndrome, received_codeword)\n",
        "\n",
        "    print(\"Decoded Codeword:\")\n",
        "    print(decoded_codeword)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlHOecZpUhFN",
        "outputId": "94b4e4b1-d58e-470a-9bc1-89ba75143616"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Codeword: [0 0 0 0 0 0]\n",
            "Error Pattern: [0 1 0 0 0 0]\n",
            "Received Codeword: [0 1 0 0 0 0]\n",
            "Syndrome: [1 1 0 0]\n",
            "Decoded Codeword:\n",
            "[0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nA86XsDFaFX_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
